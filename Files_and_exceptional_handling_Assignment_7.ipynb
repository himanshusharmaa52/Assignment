{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Q1. Discuss the scenarios where multithreading is preferable to multiprocessing and scenarios where multiprocessing is a better choice.**\n",
        "\n",
        "**Ans:** When deciding between multithreading and multiprocessing, it is important to understand their fundamental differences and how each approach performs under different conditions.\n",
        "\n",
        " Let's break down the scenarios where each is preferable.\n",
        "\n",
        "**Multithreading: Preferable Scenarios**\n",
        "\n",
        "Multithreading allows multiple threads to run within a single process, sharing the same memory space. It's generally used for tasks that involve concurrent activities, but not necessarily heavy computation.\n",
        "\n",
        "1. I/O-Bound Tasks\n",
        "\n",
        "Use case: When the program spends a significant amount of time waiting for external resources, such as reading from disk, fetching data over the network, or interacting with databases.\n",
        "\n",
        "Example: A web server processing requests, a file downloader, or a web scraper.\n",
        "\n",
        "Why it works: In I/O-bound tasks, the CPU isn't always the bottleneck; the system is often waiting for data from an external resource. Multithreading allows other threads to continue working while one thread is blocked waiting for I/O, making efficient use of the available CPU.\n",
        "\n",
        "2. Lightweight Tasks with High Concurrency\n",
        "\n",
        "Use case: Tasks that are relatively lightweight in terms of computation but need to be executed concurrently.\n",
        "\n",
        "Example: Handling multiple user requests in a chat application, managing concurrent network connections in a real-time service, or processing small pieces of data in parallel.\n",
        "\n",
        "Why it works: Threads are lighter weight than processes and share the same memory space. This makes creating and managing a large number of threads easier and more efficient for lightweight tasks that don't require a lot of CPU resources.\n",
        "\n",
        "3. Shared State or Data\n",
        "\n",
        "Use case: When multiple tasks need to share common data, and synchronization is required.\n",
        "\n",
        "Example: A thread pool processing tasks that need to modify a shared data structure like a cache or buffer, or a simulation where different threads share common state.\n",
        "\n",
        "Why it works: Since threads share the same memory space, accessing and modifying shared data is simpler than with multiprocessing, where processes would require inter-process communication (IPC) mechanisms.\n",
        "\n",
        "4. Low Overhead\n",
        "\n",
        "Use case: When creating multiple concurrent units of work should have minimal overhead, and the tasks do not require heavy CPU processing.\n",
        "\n",
        "Example: A simple file processor handling a large number of small files or a web crawler fetching pages from different URLs.\n",
        "\n",
        "Why it works: Threads are lightweight, and the overhead for creating and switching between them is smaller than processes, which require separate memory and more extensive context switching.\n",
        "\n",
        "**Multiprocessing: Preferable Scenarios**\n",
        "\n",
        "Multiprocessing involves running multiple processes, each with its own memory space. This approach is ideal for CPU-bound tasks and tasks requiring isolation.\n",
        "\n",
        "1. CPU-Bound Tasks\n",
        "\n",
        "Use case: When the program performs computationally intensive operations that consume a lot of CPU time, such as number crunching, image processing, or machine learning.\n",
        "\n",
        "Example: A program that performs heavy mathematical calculations, a scientific simulation, or data analysis involving large datasets (like matrix operations or image transformation).\n",
        "\n",
        "Why it works: In languages like Python, multithreading cannot fully utilize multiple cores for CPU-bound tasks due to the Global Interpreter Lock (GIL). Multiprocessing allows each process to run on its own CPU core, enabling true parallelism and better CPU utilization.\n",
        "\n",
        "2. True Parallelism\n",
        "\n",
        "Use case: Tasks that benefit from running in parallel across multiple CPU cores.\n",
        "\n",
        "Example: Parallel processing of large datasets, rendering in 3D modeling, or training machine learning models in parallel.\n",
        "\n",
        "Why it works: Each process runs independently on separate cores, allowing the program to take full advantage of multi-core processors. This is particularly useful for tasks that can be divided into independent, parallelizable chunks.\n",
        "\n",
        "3. Isolation and Fault Tolerance\n",
        "\n",
        "Use case: When tasks need to be isolated from each other to avoid crashes or interference between processes, or when you want to run tasks in completely separate environments.\n",
        "\n",
        "Example: Running multiple services or microservices on the same system, processing large chunks of data where one task's failure should not impact others, or handling sensitive data where processes need to be isolated for security or reliability reasons.\n",
        "\n",
        "Why it works: Processes do not share memory space, so they are more isolated from each other compared to threads. This isolation makes it easier to manage crashes, exceptions, and memory leaks in one process without affecting others.\n",
        "\n",
        "4. Avoiding Global Interpreter Lock (GIL)\n",
        "\n",
        "Use case: In languages like Python, where the GIL limits the execution of threads in a single process, making multithreading less effective for CPU-bound tasks.\n",
        "\n",
        "Example: A data-intensive application or scientific computation that requires high levels of parallelism (e.g., a large-scale simulation or a deep learning model training process).\n",
        "\n",
        "Why it works: Each process in multiprocessing has its own memory space and runs independently, so it bypasses the GIL and can utilize multiple CPU cores fully.\n",
        "\n",
        "5. High Memory Requirement\n",
        "\n",
        "Use case: When each task needs significant memory and it’s better to isolate them to avoid conflicts.\n",
        "\n",
        "Example: A machine learning model that needs a significant amount of memory to train and requires separation from other processes.\n",
        "\n",
        "Why it works: Each process in multiprocessing has its own memory space, so tasks that require a large amount of memory can be isolated from others, avoiding memory conflicts and ensuring that one task doesn't affect the memory usage of another.\n",
        "\n"
      ],
      "metadata": {
        "id": "xQbqJYzFps4k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q2. Describe what a process pool is and how it helps in managing multiple processes efficiently.**\n",
        "\n",
        "**Ans:** A process pool allows for the management of multiple processes by reusing processes instead of creating and destroying them repeatedly. This can be particularly useful when there is a need to handle many computationally intensive tasks in parallel, such as in parallel computing, web servers, or data processing.\n",
        "\n",
        "**Benefits of Using a Process Pool**\n",
        "\n",
        "1. Resource Efficiency\n",
        "\n",
        "Creating and destroying processes can be expensive in terms of time and system resources. A process pool reduces this overhead by maintaining a fixed number of worker processes that can be reused for different tasks, ensuring efficient utilization of system resources.\n",
        "With a pool, you avoid the cost of process creation and destruction for each task.\n",
        "\n",
        "2. Improved Performance\n",
        "\n",
        "By reusing processes, you avoid the delays associated with repeatedly forking new processes. Additionally, the system can balance the workload across multiple worker processes, which can lead to better CPU utilization.\n",
        "Pooling is particularly beneficial in scenarios where tasks are computationally expensive (CPU-bound) and need to be executed in parallel, as the work is divided across multiple cores.\n",
        "\n",
        "3. Concurrency and Parallelism\n",
        "\n",
        "A process pool can help with parallelism by utilizing multiple CPU cores. Each worker process in the pool can run independently on different cores, allowing tasks to run concurrently in a multi-core system, thereby improving throughput and speed for CPU-heavy tasks.\n",
        "The pool can be set to match the number of CPU cores on the system, optimizing the use of available cores and maximizing performance.\n",
        "\n",
        "4. Task Management and Scheduling\n",
        "\n",
        "A process pool simplifies the management of tasks by abstracting away the details of process creation and termination. Instead of manually managing each process, tasks can be submitted to the pool, which automatically handles the scheduling of tasks across the available worker processes.\n",
        "Some advanced pool managers can even implement load balancing, which ensures that tasks are evenly distributed among processes, preventing idle workers and minimizing bottlenecks.\n",
        "\n",
        "5. Avoiding Blocking\n",
        "A process pool can be especially useful when there are tasks that may block (e.g., waiting on I/O operations). By using a pool, a worker process that is blocked on one task can be freed up to handle another task, thus keeping the system efficient and responsive.\n",
        "\n",
        "6. Scalability\n",
        "\n",
        "A process pool can scale dynamically to handle an increasing number of tasks. In some implementations, the pool can grow or shrink based on demand, allowing the system to adapt to workload changes.\n"
      ],
      "metadata": {
        "id": "K14pRjGKq_Lq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q3. Explain what multiprocessing is and why it is used in Python programs.**\n",
        "\n",
        "**Ans:** Multiprocessing is a programming paradigm that allows a program to run multiple processes in parallel. Each process operates independently and has its own memory space. In the context of Python, multiprocessing refers to the ability of a Python program to use multiple processes (rather than threads) to execute tasks concurrently, taking full advantage of multi-core processors.\n",
        "\n",
        "Each process in a multiprocessing system runs in its own memory space and operates independently, which provides true parallelism. This is especially useful for CPU-bound tasks, where the goal is to maximize CPU utilization by running tasks on multiple CPU cores simultaneously.\n",
        "\n",
        "**The main reasons why multiprocessing is used in Python programs:**\n",
        "\n",
        "1. Bypassing the GIL (Global Interpreter Lock) for True Parallelism\n",
        "\n",
        "**Problem with the GIL:**\n",
        "In CPython (the standard Python implementation), the GIL restricts the execution of multiple threads in a single process. While threads can be used for I/O-bound tasks (like network requests or file I/O), the GIL severely limits CPU-bound tasks because only one thread can execute Python bytecode at a time, even on multi-core machines.\n",
        "\n",
        "**Solution with Multiprocessing:** By using multiprocessing, each process runs in its own memory space and has its own GIL, so multiple processes can run in parallel on multiple CPU cores. This allows the program to take full advantage of multi-core processors, achieving true parallelism for CPU-heavy operations.\n",
        "\n",
        "2. Parallelizing CPU-Bound Tasks\n",
        "\n",
        "**CPU-Bound Tasks:** These are tasks that require significant computation, such as complex calculations, data analysis, simulations, or machine learning. These tasks are often bottlenecked by the processing power of a single CPU core.\n",
        "\n",
        "**Multiprocessing Solution:** With multiprocessing, you can distribute the work of CPU-bound tasks across multiple cores, allowing the system to complete the task faster. For example, if a task can be divided into smaller, independent sub-tasks, multiprocessing allows each sub-task to run in parallel on different CPU cores, greatly speeding up the overall process.\n",
        "\n",
        "3. Process Isolation for Fault Tolerance\n",
        "\n",
        "**Process Isolation:** Each process in a multiprocessing system runs in its own memory space. This isolation means that if one process encounters an error or crashes, it doesn't affect the other processes. This makes multiprocessing ideal for creating more robust and fault-tolerant systems.\n",
        "\n",
        "**Python's GIL:** With threads, because they share the same memory space, one thread’s failure can potentially bring down the entire program. However, with multiprocessing, each process is isolated, so a failure in one process does not impact the others.\n"
      ],
      "metadata": {
        "id": "-BhSsKiTsJuz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q4. Write a Python program using multithreading where one thread adds numbers to a list, and another thread removes numbers from the list. Implement a mechanism to avoid race conditions using threading.Lock.**\n",
        "\n"
      ],
      "metadata": {
        "id": "K0LC5HUrtrHj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import threading\n",
        "import time\n",
        "import random\n",
        "\n",
        "# Shared list\n",
        "shared_list = []\n",
        "# Lock to synchronize access to the shared list\n",
        "lock = threading.Lock()\n",
        "\n",
        "# Function to add numbers to the list\n",
        "def add_numbers():\n",
        "    for _ in range(10):\n",
        "        number = random.randint(1, 100)  # Generate a random number\n",
        "        with lock:  # Ensure exclusive access to shared_list\n",
        "            shared_list.append(number)\n",
        "            print(f\"Added {number} to the list.\")\n",
        "        time.sleep(random.uniform(0.1, 0.5))  # Simulate some delay\n",
        "\n",
        "# Function to remove numbers from the list\n",
        "def remove_numbers():\n",
        "    for _ in range(10):\n",
        "        with lock:  # Ensure exclusive access to shared_list\n",
        "            if shared_list:  # Check if the list is not empty\n",
        "                removed = shared_list.pop(0)  # Remove the first element from the list\n",
        "                print(f\"Removed {removed} from the list.\")\n",
        "            else:\n",
        "                print(\"List is empty, nothing to remove.\")\n",
        "        time.sleep(random.uniform(0.1, 0.5))  # Simulate some delay\n",
        "\n",
        "# Create threads for adding and removing numbers\n",
        "add_thread = threading.Thread(target=add_numbers)\n",
        "remove_thread = threading.Thread(target=remove_numbers)\n",
        "\n",
        "# Start the threads\n",
        "add_thread.start()\n",
        "remove_thread.start()\n",
        "\n",
        "# Wait for both threads to finish\n",
        "add_thread.join()\n",
        "remove_thread.join()\n",
        "\n",
        "print(\"Final state of the list:\", shared_list)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FIHWi36KzqRM",
        "outputId": "b517fbf3-b9a2-4a95-d761-9a8f2495ba74"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Added 18 to the list.\n",
            "Removed 18 from the list.\n",
            "List is empty, nothing to remove.\n",
            "Added 94 to the list.\n",
            "Removed 94 from the list.\n",
            "Added 75 to the list.\n",
            "Added 34 to the list.\n",
            "Removed 75 from the list.\n",
            "Added 9 to the list.\n",
            "Removed 34 from the list.\n",
            "Removed 9 from the list.\n",
            "Added 79 to the list.\n",
            "Added 96 to the list.\n",
            "Removed 79 from the list.\n",
            "Removed 96 from the list.\n",
            "List is empty, nothing to remove.\n",
            "Added 1 to the list.\n",
            "Added 72 to the list.\n",
            "Removed 1 from the list.\n",
            "Added 79 to the list.\n",
            "Final state of the list: [72, 79]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q5. Describe the methods and tools available in Python for safely sharing data between threads and processes.**\n",
        "\n",
        "Ans: **Sharing Data Between Threads**\n",
        "\n",
        "Threads share the same memory space in a Python program, so they can directly access and modify common variables. However, because of this shared memory, threads can potentially interfere with each other (i.e., race conditions) when accessing shared data simultaneously. To handle these issues, Python provides synchronization tools.\n",
        "\n",
        "1. threading.Lock (Mutual Exclusion Lock)\n",
        "\n",
        "**Description:** A Lock is the most basic tool for synchronizing threads. It ensures that only one thread can execute a block of code at any given time.\n",
        "\n",
        "**Usage:** When multiple threads need to access shared resources (like a list or dictionary), a lock can be used to prevent race conditions by making sure that only one thread accesses the resource at a time.\n",
        "\n",
        "2. threading.RLock (Reentrant Lock)\n",
        "\n",
        "**Description:** An RLock is a type of lock that can be acquired multiple times by the same thread. It is useful when a thread needs to acquire the lock several times during its execution (e.g., recursive functions).\n",
        "\n",
        "**Usage:** You would use an RLock when you need to acquire the same lock multiple times within the same thread.\n",
        "\n",
        "3. threading.Condition\n",
        "\n",
        "**Description:** A Condition allows threads to wait for certain conditions to be met (like a flag variable being set). It’s useful when you need one or more threads to wait for another thread to reach a certain state before continuing.\n",
        "\n",
        "**Usage:** Often used in producer-consumer problems, where one thread produces data and another consumes it.\n",
        "\n",
        "**Sharing Data Between Processes**\n",
        "\n",
        "Unlike threads, processes run in separate memory spaces. This means that sharing data between processes is more complex than sharing data between threads. Python provides several tools to safely share data between processes and manage inter-process communication (IPC).\n",
        "\n",
        "1. multiprocessing.Queue\n",
        "\n",
        "**Description:** A Queue is a thread- and process-safe data structure used for passing data between processes. It works similarly to a queue in threading, but it’s specifically designed for processes.\n",
        "\n",
        "**Usage:** Queue can be used to send data from one process to another in a producer-consumer setup.\n",
        "\n",
        "2. multiprocessing.Pipe\n",
        "\n",
        "**Description:** A Pipe is another form of IPC between two processes. It allows bidirectional communication between two processes. Pipes are low-level, and you have to handle the reading and writing manually.\n",
        "\n",
        "**Usage:** Useful for direct communication between two processes where you need to send messages back and forth.\n",
        "\n",
        "3. multiprocessing.Manager (for Shared Data)\n",
        "\n",
        "**Description:** A Manager provides a way to create objects that can be shared between processes, such as lists, dictionaries, and other data structures. The objects are managed by a server process and can be safely accessed by other processes.\n",
        "\n",
        "**Usage:** Use Manager when you need shared, mutable data structures across processes.\n"
      ],
      "metadata": {
        "id": "Q01GHaZNutpm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q6. Discuss why it's crucial to handle exceptions in concurrent programs and the techniques available for doing so.**\n",
        "\n",
        "**Ans:**  **Exception Handling is Crucial in Concurrent Programs**\n",
        "\n",
        "1. Uncaught Exceptions in Threads or Processes:\n",
        "\n",
        "In multi-threaded programs, an exception in one thread won't automatically propagate to the main thread or other threads. If a thread fails and the exception is not handled, it might lead to inconsistent program state or cause the thread to exit unexpectedly, leaving shared resources in an indeterminate state.\n",
        "\n",
        "In multi-process programs, if a process encounters an error, it won't directly affect other processes, but if the exception is not handled within the process, it can lead to missed data, incomplete tasks, or even deadlock in systems relying on inter-process communication.\n",
        "\n",
        "2. Preventing Program Crashes:\n",
        "\n",
        "If an exception is not handled, it can cause the program to terminate unexpectedly. In concurrent programs, this can be particularly harmful because it might cause data loss, incomplete computations, or inconsistent results. Proper exception handling allows the program to recover or gracefully shut down instead of abruptly crashing.\n",
        "\n",
        "3. Ensuring Reliable Resource Management:\n",
        "\n",
        "Concurrent programs often involve shared resources, such as files, databases, and memory. Unhandled exceptions in a thread or process can leave resources in an inconsistent state, possibly causing memory leaks, file corruption, or database inconsistency. Exception handling ensures that these resources are properly released, cleaned up, or rolled back when an error occurs.\n",
        "\n",
        "4. Debugging and Logging:\n",
        "\n",
        "Handling exceptions in a controlled manner allows you to log useful error information, making it easier to debug the program and understand what went wrong in a specific thread or process. Without proper logging or exception handling, debugging becomes significantly harder, especially in complex concurrent systems.\n",
        "\n",
        "**Techniques for Handling Exceptions in Concurrent Programs are:**\n",
        "\n",
        "1. Handling Exceptions in Threads\n",
        "\n",
        "A. Using try-except Blocks in Threads\n",
        "\n",
        "The simplest method for handling exceptions in threads is by enclosing the code that might raise an exception in a try-except block within the target function of the thread.\n",
        "\n",
        "B. Using ThreadPoolExecutor and Future Objects\n",
        "\n",
        "If you are using a ThreadPoolExecutor to manage multiple threads, exceptions can be caught when retrieving the results using the Future object. The Future object represents the result of a computation that may not have completed yet, and it allows checking if the computation was successful or raised an exception.\n",
        "\n",
        "2. Handling Exceptions in Processes\n",
        "\n",
        "A. Using try-except Blocks in Processes\n",
        "\n",
        "Just like with threads, you can use try-except blocks to catch exceptions within the target function of a process.This ensures that exceptions within individual processes are caught and can be logged or handled.\n",
        "\n",
        "B. Using Pool and apply_async()\n",
        "\n",
        "In a pool of worker processes, exceptions raised in any process can be captured using the apply_async() method, which returns a result object (similar to Future in threads). You can check if the task was successful or if an exception occurred.\n",
        "\n",
        "C. Using multiprocessing.Manager for Shared Data\n",
        "\n",
        "In case shared data structures are being used, and you need to manage exceptions across processes, a Manager object can help coordinate exception handling, as it allows sharing state across processes.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "6-hkgfMGw8IF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q7. Create a program that uses a thread pool to calculate the factorial of numbers from 1 to 10 concurrently. Use concurrent.futures.ThreadPoolExecutor to manage the threads.**\n"
      ],
      "metadata": {
        "id": "pS7XLq8czdqv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import concurrent.futures\n",
        "import math\n",
        "\n",
        "\n",
        "def calculate_factorial(n):\n",
        "    return math.factorial(n)\n",
        "\n",
        "def main():\n",
        "\n",
        "    with concurrent.futures.ThreadPoolExecutor() as executor:\n",
        "\n",
        "        futures = [executor.submit(calculate_factorial, i) for i in range(1, 11)]\n",
        "\n",
        "        for future in concurrent.futures.as_completed(futures):\n",
        "            result = future.result()\n",
        "            print(result)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bdg9VwQC0h_h",
        "outputId": "f9f5bd86-b1da-4db7-cd5b-5fd3b2eec9c5"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24\n",
            "1\n",
            "362880\n",
            "120\n",
            "3628800\n",
            "6\n",
            "2\n",
            "40320\n",
            "5040\n",
            "720\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q8. Create a Python program that uses multiprocessing.Pool to compute the square of numbers from 1 to 10 in parallel. Measure the time taken to perform this computation using a pool of different sizes (e.g., 2, 4, 8 processes)."
      ],
      "metadata": {
        "id": "iuugEjUM0r5b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import multiprocessing\n",
        "import time\n",
        "\n",
        "# Function to compute the square of a number\n",
        "def compute_square(n):\n",
        "    return n * n\n",
        "\n",
        "def measure_time(pool_size):\n",
        "    # Measure the time taken to compute squares with a given pool size\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Create a Pool of processes\n",
        "    with multiprocessing.Pool(pool_size) as pool:\n",
        "        # Using pool.map to apply the function to each number in the range\n",
        "        results = pool.map(compute_square, range(1, 11))\n",
        "\n",
        "    end_time = time.time()\n",
        "    elapsed_time = end_time - start_time\n",
        "    print(f\"Time taken with {pool_size} processes: {elapsed_time:.4f} seconds\")\n",
        "\n",
        "    return results\n",
        "\n",
        "def main():\n",
        "    # Test the performance with different pool sizes\n",
        "    pool_sizes = [2, 4, 8]\n",
        "\n",
        "    for pool_size in pool_sizes:\n",
        "        print(f\"\\nComputing squares with pool size {pool_size}...\")\n",
        "        results = measure_time(pool_size)\n",
        "        print(f\"Squares: {results}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eXrTh7kC1PDN",
        "outputId": "9f15975a-c0a1-4095-aa5d-8a67b0107938"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Computing squares with pool size 2...\n",
            "Time taken with 2 processes: 0.0333 seconds\n",
            "Squares: [1, 4, 9, 16, 25, 36, 49, 64, 81, 100]\n",
            "\n",
            "Computing squares with pool size 4...\n",
            "Time taken with 4 processes: 0.0467 seconds\n",
            "Squares: [1, 4, 9, 16, 25, 36, 49, 64, 81, 100]\n",
            "\n",
            "Computing squares with pool size 8...\n",
            "List is empty, waiting for numbers to be added.\n",
            "List is empty, waiting for numbers to be added.\n",
            "Time taken with 8 processes: 0.1035 seconds\n",
            "Squares: [1, 4, 9, 16, 25, 36, 49, 64, 81, 100]\n"
          ]
        }
      ]
    }
  ]
}